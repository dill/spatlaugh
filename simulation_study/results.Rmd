---
title: "Results from spatial simulations"
author: "David L Miller and Mark V Bravington"
output: html_document
number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache=TRUE)
```

```{r load-pkg}
library(ggplot2)
library(reshape2)
library(plyr)
library(viridis)
```

# Simulation setup

- No group size issues -- everything is group size 1
- No issues with $\hat{g}(0)$
- Ignoring the possibility of repeat surveys


## Spatial models

* Isotropic smooths
    * Thin plate spline (`bs="tp"`)
    * Thin plate spline with shrinkage (`bs="ts"`)
    * Duchon spline (`bs="ds", m=c(1, 0.5)`)
    * Thin plate spline with rotated covariates (`bs="tp"`)
* Tensor product smooths
    * Thin plate spline (`bs="tp"`)
    * Thin plate spline with rotated covariates (`bs="tp"`)

In the rotated covariate case, the coordinates were rotated through 45$^o$ by the rotation matrix:
$$
R= \begin{pmatrix}
   \cos(\pi/4) & -\sin(\pi/4)\\
   \sin(\pi/4) & \cos(\pi/4)
   \end{pmatrix}
$$

## Non-spatially explicit models

- Horvitz-Thompson
- Horvitz-Thompson stratified with 2 strata: $x\leq 0.5$ and $x>0.5$.

## True distributions

- "`f`": flat density, uniform distribution across the region.
- "`lr`": left to right gradient, high on the left, decreasing as we go right.
- "`rl`": right to left gradient, high on the right, decreasing as we go left.
- "`rl_002`": right to left, but decreasing the detectability (i.e., decreasing teh effective strip width).
- "`rl_001`": right to left, but severely decreasing the detectability (i.e., decreasing the effective strip width).


```{r density-surfaces, fig.width=9, fig.height=3, echo=FALSE}

par(mfrow=c(1,3))
n_grid_x <- 300
n_grid_y <- 100

density.surface <- expand.grid(x = seq(0, 3, len=n_grid_x),
                               y = seq(0, 1, len=n_grid_y))

densities <- list(rep(1, length(density.surface$x)),
                  rev(density.surface$x),
                  density.surface$x,
                  rev(density.surface$x),
                  rev(density.surface$x))
names <- list("f", "lr", "rl", "rl_002", "rl_001")
  
for(i in 1:3){
  image(matrix(densities[[i]], n_grid_x, n_grid_y),
        x=seq(0, 3, len=n_grid_x),
        y= seq(0, 1, len=n_grid_y),
        col = viridis(1000), main=names[[i]],
        xlab="x", ylab="y", asp=1)
  
}

```

## Detectability

Detections were generated using a hazard-rate detection function with a scale parameter of 0.03 (except in the `rl_002` and `rl_001` cases, where it was set to 0.02 and 0.01, respectively) and a shape parameter of 3 (except in the `rl_002` and `rl_001` cases, where it was set to 1.5 and 1.1, respectively).

Models were fitted assuming the form of the detection function (hazard-rate) was known, as well as the truncation distance (set as simulated from).

## Designs

### Design 1 -- zig-zag with straight line

This is supposed to mimic the situation in which a zig-zag design went well on the left side of the study area, but not realised in the middle of the survey (perhaps due to bad weather), then to the left we have a lonely transect (perhaps weather picked-up).

```{r designs, echo=FALSE, fig.width=4, fig.height=4}
n_segs <- 10

zz <- data.frame(x   = c(seq(0, 0.5, len=n_segs),
                         seq(0.5, 1, len=n_segs)),
                 y   = c(seq(0, 1, len=n_segs),
                         seq(1, 0, len=n_segs)),
                 leg = c(rep("1", n_segs),
                         rep("2", n_segs)))

# many zigzags
mzz <- rbind(zz,zz,zz)

mzz$x <- mzz$x/3
ind <- 1:nrow(zz)
mzz$x[ind+nrow(zz)] <- mzz$x[ind+nrow(zz)]+1/3
mzz$x[ind+2*nrow(zz)] <- mzz$x[ind+2*nrow(zz)]+2/3


mzz$leg <- as.numeric(mzz$leg)
mzz$leg[ind+nrow(zz)] <- mzz$leg[ind+nrow(zz)]+2
mzz$leg[ind+2*nrow(zz)] <- mzz$leg[ind+2*nrow(zz)]+4
mzz$leg <- as.character(mzz$leg)


zzl <- rbind.data.frame(mzz,
                        data.frame(x   = rep(2.8, 10),
                                   y   = seq(0, 1, len=10),
                                   leg = rep(as.character(max(as.numeric(mzz$leg))+1), 10)))

plot(c(0,3),c(0,1), type="n", xlab="x", ylab="y", asp=1)
for(i in unique(zzl$leg)){
  lines(zzl[,c("x","y")][zzl$leg==i,])
}

lines(c(0,3,3,0,0), c(0,0,1,1,0))

```

## Metrics

### Bias

We can simply calculate the bias ($N_\text{truth} -\hat{N}$) and plot boxplots of these values, however this does not get to the uncertainty, which we're more intrested in...

### Where does the truth lie in the distribution of the model?

If we know $N_\text{truth}$ then at what quantile does it lie in the distribution implied by the model, so find $\mathbb{P}[N_\text{truth} \leq \hat{N}]$. Here we assume log-normally distributed $\hat{N}$, so we can use `plnorm` in R to calculate the value we require. This summary statistic gives some idea of both bias and variance.

If the distribution of the statistic is skewed to either end then we can infer under or over estimation of abundance. Flat distribution is good, a "dome" in the middle indicates a conservative estimate (CIs slightly too wide), which we like.

# Results

```{r load-and-plot-results, echo=FALSE, fig.width=11, fig.height=4.5, warning=FALSE, message=FALSE, results="asis"}
# what are the filenames?
# one for each distribution/detectability
f_names <- c("f.RData", "lr.RData", "rl.RData",
             "rl_002.RData", "rl_001.RData")

# lookup for model names to short descriptions
model_name_lookup <- list("HT" = "Horvitz-Thompson",
                          "HT_strat" = "Horvitz-Thompson (stratified)",
                          "m_xy_ds"  = "Duchon spline bivariate",
                          "m_xy_te"  = "Thin plate tensor product",
                          "m_xy_tp"  = "Thin plate bivariate",
                          "m_xy_ts"  = "Thin plate with shrinkage bivariate",
                          "m_xyr_tp"  = "Thin plate bivariate rotated",
                          "m_xyr_te"  = "Thin plate tensor product rotated"
                          )

# helper functions
reasonable_range <- function(x){
  # 1 and 5 are whiskers
  boxplot.stats(x)$stats[c(1,5)]
}
clipped_obs <- function(x, rr, name){
  x <- x[[name]]
  length(x[x<=rr[1] | x>=rr[2]])
}

# now loop over the files
for(i in seq_along(f_names)){
  
  load(f_names[i])
  
  # re-arrange column names
  big_res$N <- big_res$V1
  big_res$CV <- big_res$V2
  big_res$V1 <- big_res$V2 <- NULL
  big_res$se <- big_res$CV*big_res$N
  big_res$sen <- big_res$se/sqrt(big_res$n)
  
  # does 1/smoothing parameter make more sense (no?)
  big_res$sp1 <- 1/big_res$sp1
  big_res$sp2 <- 1/big_res$sp2
  
  # print the name of this scenario as the header
  f_names[i] <- sub(".RData", "", f_names[i])
  cat("\n\n## ", f_names[i],"\n\n")
  
  ## N
  rr <- reasonable_range(big_res$N)
  # build a data.frame to count clipped observation
  clipped_d <- ddply(big_res, .(names), clipped_obs, name="N", rr=rr)
  
  #p <- ggplot(big_res)+
  #  geom_histogram(aes(N))+
  #  facet_wrap(~names, scales="free_x",nrow=2)+
  #  ggtitle(paste(f_names[i], "N"))+
  #  scale_x_continuous(limits = rr) +
  #  geom_text(aes(label=V1, x=rr[1]+(rr[2]-rr[1]), y=50 ), data=clipped_d) +
  #  geom_vline(aes(xintercept=200))
  #print(p) 
  
  # bias boxplot
  big_res$bias <- big_res$N-200
  p <- ggplot(big_res)+
    geom_boxplot(aes(names, bias)) +
    #facet_wrap(~names, scales="free_x",nrow=2)+
    ggtitle("Bias") +
    labs(y="Bias") +
    coord_cartesian(ylim=c(-200,300)) +
    theme_minimal() +
    geom_hline(aes(yintercept=0), colour="red")
  print(p) 
  
  # Mark's fancy quantile diagnostic, described above
  p <- ggplot(big_res)+
    geom_histogram(aes(quantile))+
    facet_wrap(~names, nrow=2)+
    ggtitle("Quantile diagnostic") +
    theme_minimal()
  print(p) 
  
  #rr <- reasonable_range(big_res$sen)
  ## build a data.frame to count clipped observation
  #clipped_d <- ddply(big_res, .(names), clipped_obs, name="sen", rr=rr)
  #p <- ggplot(big_res)+
  #  geom_histogram(aes(sen))+
  #  facet_wrap(~names, scales="free_x",nrow=2)+
  #  scale_x_continuous(limits = rr) +
  #  geom_text(aes(label=V1, x=rr[1]+(rr[2]-rr[1]), y=50 ), data=clipped_d) +
  #  ggtitle(paste(f_names[i], "se/sqrt(n)"))
  #print(p) 
  #
  ## smoothing parameters
  #sp_dat <- big_res[!(big_res$names %in% c("HT","HT_strat")),]
  #sp_dat$names <- as.character(sp_dat$names)
  #
  ## mash the sp2s into the sp1 data
  #sp_dat2 <- big_res[big_res$names %in% c("m_xy_te","m_xyr_te"),]
  #sp_dat2$names <- as.character(sp_dat2$names)
  #sp_dat2$names[sp_dat2$names=="m_xy_te"] <- "m_xy_te sp2"
  #sp_dat2$names[sp_dat2$names=="m_xyr_te"] <- "m_xyr_te sp2"
  #sp_dat <- rbind(sp_dat,sp_dat2)
  #sp_dat$names <- as.factor(sp_dat$names)
  #
  #sp_dat$names <- droplevels(sp_dat$names)
  #rr <- reasonable_range(sp_dat$sp1)
  ## build a data.frame to count clipped observation
  #clipped_d <- ddply(sp_dat, .(names), clipped_obs, name="sp1", rr=rr)
  #p <- ggplot(sp_dat)+
  #  geom_histogram(aes(sp1))+
  #  facet_wrap(~names, scales="free_x",nrow=2)+
  #  ggtitle(paste(f_names[i], "1/sp1"))
  #print(p) 
  
}
```


## Number of detections per simulation

```{r detections, echo=FALSE, fig.width=15, fig.height=4, warning=FALSE, message=FALSE}
f_names <- c("f.RData", "lr.RData", "rl.RData", "rl_002.RData", "rl_001.RData")
ndat <- c()
for(i in seq_along(f_names)){
  load(f_names[i])
  ndat <- rbind(ndat,
                cbind(scenario=sub(".RData", "", f_names[i]),
                      big_res[big_res$name=="HT",])
                )
}
p <- ggplot(ndat)+
  geom_histogram(aes(n), binwidth=2)+
  ggtitle("detections") +
  facet_wrap(~scenario, nrow=1) +
  theme_minimal()
print(p) 
```



