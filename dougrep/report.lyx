#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass article
\use_default_options true
\begin_modules
knitr
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman ae
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Shortcomings of Horvitz-Thompson-based estimates of abundance for large-scale
 cetacean abundance estimation
\end_layout

\begin_layout Author
David L.
 Miller and Mark V.
 Bravington
\end_layout

\begin_layout Address
Integrated Statistics, Woods Hole, MA & Centre for Research into Ecological
 and Environmental Modelling, St Andrews, Scotland
\end_layout

\begin_layout Address
Commonwealth Scientific and Industrial Research Organization, Hobart, TAS
\end_layout

\begin_layout Section
Introduction 
\end_layout

\begin_layout Standard
A great deal of time and money is spent on large-scale cetacean surveys.
 Though sophisticated statistical methods have been developed to deal with
 the complications of complex spatial data, it can be the case that investigator
s opt for an overly simplistic analysis based on randomization principles
 which are not appropriate for the data in question.
 An example of a potential issue of this type is the use of 
\begin_inset Quotes eld
\end_inset

vanilla
\begin_inset Quotes erd
\end_inset

 Horvitz-Thompson estimators of abundance from line transect surveys when
 the underlying distribution of the study species in fact varies in space.
 In this paper we show by simulation when such analyses are inappropriate
 in simple situations -- appealing to the line of reasoning that if an estimator
 shows poor properties in a simple situation, then when the distribution,
 availability or detectability is more complex in nature then the estimator
 will perform even more poorly.
\end_layout

\begin_layout Standard
In this paper we are interested in two methodologies for estimating abundance
 from line transect distance sampling surveys, one is a design-based estimate,
 the other is a model-based estimate.
 We assume in both cases that the usual assumptions regarding distance sampling
 surveys have been met (see e.g., Buckland et al 2001, 2004, 2015).
 We also assume that distances are recorded for each observation (along
 with the size of each group of animals, without error).
 Each 
\shape italic
realized
\shape default
 transect position is recorded (for example using an automated waypoint
 function on a GPS unit), i.e., the transect lines are recorded as they were
 visited, rather than as they were designed.
 As transects were recorded, an covariate that gives some indication of
 sighting conditions should also be recorded (we simply refer to this as
 
\begin_inset Quotes eld
\end_inset

weather
\begin_inset Quotes erd
\end_inset

 but it could be Beaufort Sea State or some other omnibus measure of visual
 conditions).
 We now describe the two ways in which one could analyze this data, as used
 in this paper.
\end_layout

\begin_layout Standard

\series bold
Say something here about how we assume that the detectability is estimated
 already.
\end_layout

\begin_layout Standard
We first describe the 
\begin_inset Quotes eld
\end_inset

Horvitz-Thompson-like
\begin_inset Quotes erd
\end_inset

 estimator (henceforth HT) first described in (
\series bold
blah, CITE
\series default
).
 In its simplest version, the HT estimator is
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\hat{N}=\frac{A}{a}\sum_{i=1}^{n}\frac{s_{i}}{\hat{p}_{i}}
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $n$
\end_inset

 is the number of observations, index by 
\begin_inset Formula $i$
\end_inset

, 
\begin_inset Formula $s_{i}$
\end_inset

 is the size of the 
\begin_inset Formula $i^{\text{th}}$
\end_inset

 group and 
\begin_inset Formula $\hat{p}_{i}$
\end_inset

 is the detectability estimated for the 
\begin_inset Formula $i^{\text{th}}$
\end_inset

 group, which will be a function of the corresponding covariates for that
 observation.
 The total area surveyed (
\shape italic
covered area
\shape default
) is 
\begin_inset Formula $a$
\end_inset

, which is the product of the line lengths and their corresponding strip
 widths (if the strips were all the same length then 
\begin_inset Formula $a=2wL$
\end_inset

, where 
\begin_inset Formula $w$
\end_inset

 is the strip half-width as in Buckland et al 2001, and 
\begin_inset Formula $L$
\end_inset

 is the sum of all the lines' lengths).
 Finally, 
\begin_inset Formula $A$
\end_inset

 is the area that we wish to estimate abundance for.
 Intuitively, we take the group sizes, correct them for detectability and
 sum to get an estimate of abundance in the covered area, we then rescale
 this according to the proportion of the covered area that the study region
 is.
 The HT estimator assumes that animal density is constant within the study
 area.
 This assumption may be justifiable in some situations, but seems very unlikely
 in a dynamic environment such as an ocean.
\end_layout

\begin_layout Standard
In order to circumvent this shortcoming, we can perform pre or post hoc
 stratification, slicing-up the study area into smaller polygons and estimating
 abundance for each of these.
 These may be geographically defined (
\begin_inset Quotes eld
\end_inset

near vs.
 far from shore
\begin_inset Quotes erd
\end_inset

, 
\begin_inset Quotes eld
\end_inset

east/west of some longitude
\begin_inset Quotes erd
\end_inset

, etc), based on conditions at sea (
\begin_inset Quotes eld
\end_inset

dense vs.
 non-dense ice
\begin_inset Quotes erd
\end_inset

) or based on oceanographic features (
\begin_inset Quotes eld
\end_inset

deep or shallow water
\begin_inset Quotes erd
\end_inset

).
 In some sense these estimates reflect a crude, 
\begin_inset Quotes eld
\end_inset

blocky
\begin_inset Quotes erd
\end_inset

 spatial model, which try to address the deeper drivers of distribution
 in a given species.
\end_layout

\begin_layout Standard
We now describe one approach to distance sampling line transect surveys
 using an explicit spatial model, which we refer to as 
\shape italic
density surface models
\shape default
 (DSMs; 
\series bold
Hedley, Miller etc
\series default
).
 These are similar to the HT estimators above, as they assume that the detection
 function has already been adequately fitted to the distance data and estimates
 of probability of detection are available for the spatial model to use.
 The spatial part of the odel uses the generalized additive modelling framework
 (
\series bold
wood, carrol etc
\series default
) to build smooth, spatially explicit terms describing the distribution
 of the species and their response to other biological/physical variables
 (though in this paper we only consider models that include smooths of location).
 Rather than dealing with whole transects (which are generally long and
 can include large changes in animal density along their length, as well
 as covariate values), we cut the transects into smaller pieces, which we
 call 
\shape italic
segments
\shape default
.
 The mean response of the model can be written as:,
\begin_inset Formula 
\[
\mathbb{E}(n_{j})=A_{j}\hat{p}_{j}\exp(\beta_{0}+\sum_{k}f_{k}(z_{kj})),
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $j$
\end_inset

 indexes the segments, each of which have area 
\begin_inset Formula $A_{j}$
\end_inset

 and all observations in that segment have a probability of detection of
 
\begin_inset Formula $\hat{p}_{j}$
\end_inset

.
 The response, 
\begin_inset Formula $n_{j}$
\end_inset

, is distributed according to some count distribution for which 
\begin_inset Formula $\exp$
\end_inset

 is the link function.
 The model intercept is 
\begin_inset Formula $\beta_{0}$
\end_inset

.
 The 
\begin_inset Formula $f_{k}$
\end_inset

 are usually splines (
\series bold
some papers
\series default
): smooth functions of one or more covariates (denoted 
\begin_inset Formula $z_{jk}$
\end_inset

), though could be more exotic things like random effects, tensor products,
 smooth-factor interactions and so forth (
\series bold
cite Simon doubly general paper
\series default
).
 The exact form of each 
\begin_inset Formula $f_{k}$
\end_inset

 depends on the nature of the effect we wish to model, for smooths of location
 there are quite a few options, some of which are enumerated and described
 below.
\end_layout

\begin_layout Section
Motivation
\end_layout

\begin_layout Standard
The DSM approach is more complex as we explicitly model the spatial and
 environmental covariate effects, but this explicit modelling is the only
 way to deal with the heterogeneity in spatial distribution of the study
 species.
 We note that an appeal to 
\begin_inset Quotes eld
\end_inset

pooling robustness
\begin_inset Quotes erd
\end_inset

 (Buckland 2004, section 11.12) does not get around this issue.
 Before explaining why, we first define and explain pooling robustness in
 a distance sampling context.

\shape italic
 
\shape default
From Burnham et al.
 (1980):
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
n\hat{f}(0)=\sum_{j=1}^{r}n_{j}\hat{f}_{j}(0)
\]

\end_inset


\end_layout

\begin_layout Standard
where there are 
\begin_inset Formula $r$
\end_inset

 strata chosen to minimize heterogeneity, 
\begin_inset Formula $n$
\end_inset

 is the total number of observations, 
\begin_inset Formula $n_{j}$
\end_inset

 is the number of observations in stratum 
\begin_inset Formula $j$
\end_inset

 and 
\begin_inset Formula $\hat{f}(0)$
\end_inset

 and 
\begin_inset Formula $\hat{f}_{j}(0)$
\end_inset

 are the pdfs of distances evaluated at zero distance for the whole sample
 and by stratum, respectively.
 Equivalently we can write:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{n}{\hat{p}}=\sum_{j=1}^{r}\frac{n_{j}}{\hat{p}_{j}}
\]

\end_inset


\end_layout

\begin_layout Standard
Intuitively, we say that pooling robustness holds, the estimates from a
 stratified analysis would be the same as those for an unstratified analysis.
 Buckland et al (2004, section 11.12) state: 
\begin_inset Quotes eld
\end_inset

if only an overall abundance estimate is required, standard methods without
 covariates are satisfactory under rather mild conditions, provided heterogeneit
y in detectability is not too extreme.
\begin_inset Quotes erd
\end_inset

 But note that this is a statement essentially about Horvitz-Thompson estimation
 in the presence of detectability heterogeneity and does not say anything
 about the case where density varies within strata -- in this case the effect
 of detectability and distribution are confounded, unless data on observation
 conditions (e.g., a weather covariate) and spatial distribution (e.g., location
 of transects) is recorded and modeled.
 A spatial model that includes data on the location of the observations
 and the sighting conditions will be able to tease apart these effects and
 attribute appropriate uncertainty.
\end_layout

\begin_layout Standard
Again this is all when 
\begin_inset Formula $g(0)=1$
\end_inset

 and only gets more complicated once we start thinking about double observer
 methods.
 Buckland et al (2004) say: 
\begin_inset Quotes eld
\end_inset

If 
\begin_inset Formula $g(0,z)$
\end_inset

 is a function of 
\begin_inset Formula $z$
\end_inset

, then the model robustness criterion fails, and we must model the heterogeneity
 to avoid bias
\begin_inset Quotes erd
\end_inset

, so if we do expect that the probability of detection at zero distance
 is influenced by covariates (which it almost surely will be), pooling robustnes
s doesn't apply anyway.
\end_layout

\begin_layout Standard
Pooling robustness is implicitly conditioned on having a 
\begin_inset Quotes eld
\end_inset

reasonable
\begin_inset Quotes erd
\end_inset

design, so appeals to it should only be made in the case where the realised
 design has (approximately) even coverage.
\end_layout

\begin_layout Standard
Given the above, there is a temptation then to fit a 
\begin_inset Quotes eld
\end_inset

dumb
\begin_inset Quotes erd
\end_inset

 spatial model and hope for the best.
 This is not the case and properly configuring a spatial model is a time-consumi
ng process requiring some 
\begin_inset Quotes eld
\end_inset

expert
\begin_inset Quotes erd
\end_inset

 judgement.
 As well as formulating, fitting and selecting between models, the investigator
 also needs to select an appropriate prediction grid, ensuring that unreasonable
 extrapolations are not made (
\series bold
maybe cite Mannocci and Conn papers here?
\series default
).
\end_layout

\begin_layout Section
Description of setup
\end_layout

\begin_layout Subsection
Density surfaces
\end_layout

\begin_layout Standard
We used a series of simple density surfaces to test for differences between
 the proposed models.
 Although animal distribution is much more complicated than the patterns
 shown below, if models fail for these simple density surfaces then it's
 likely that there will be more severe issues when more complex surfaces
 are used.
 In the simulations presented here the following surfaces were investigated:
\end_layout

\begin_layout Itemize
“f”: flat density, uniform distribution across the region.
 
\end_layout

\begin_layout Itemize
“lr”: left to right gradient, high on the left, decreasing as we go right.
 
\end_layout

\begin_layout Itemize
“rl”: right to left gradient, high on the right, decreasing as we go left.
 
\end_layout

\begin_layout Standard
These are shown in figure (blah).
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

<<fig.width=9, fig.height=3, echo=FALSE, message=FALSE, warning=FALSE>>=
\end_layout

\begin_layout Plain Layout

library(viridis)
\end_layout

\begin_layout Plain Layout

par(mfrow=c(1,3))
\end_layout

\begin_layout Plain Layout

n_grid_x <- 300
\end_layout

\begin_layout Plain Layout

n_grid_y <- 100
\end_layout

\begin_layout Plain Layout

density.surface <- expand.grid(x = seq(0, 3, len=n_grid_x),              
                  							y = seq(0, 1, len=n_grid_y))
\end_layout

\begin_layout Plain Layout

densities <- list(rep(1, length(density.surface$x)),
\end_layout

\begin_layout Plain Layout

			      rev(density.surface$x),
\end_layout

\begin_layout Plain Layout

				  density.surface$x,
\end_layout

\begin_layout Plain Layout

				  rev(density.surface$x),
\end_layout

\begin_layout Plain Layout

				 rev(density.surface$x)) 
\end_layout

\begin_layout Plain Layout

names <- list("f", "lr", "rl", "rl_002", "rl_001")    
\end_layout

\begin_layout Plain Layout

for(i in 1:3){   
\end_layout

\begin_layout Plain Layout

  image(matrix(densities[[i]], n_grid_x, n_grid_y),
\end_layout

\begin_layout Plain Layout

        x=seq(0, 3, len=n_grid_x),
\end_layout

\begin_layout Plain Layout

        y= seq(0, 1, len=n_grid_y),
\end_layout

\begin_layout Plain Layout

        col = viridis(1000), main=names[[i]],
\end_layout

\begin_layout Plain Layout

        xlab="x", ylab="y", asp=1)
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
The proposed density surfaces.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Isotropic smooths 
\end_layout

\begin_deeper
\begin_layout Itemize
Thin plate spline (bs="tp")
\end_layout

\begin_layout Itemize
Thin plate spline with shrinkage (bs="ts")
\end_layout

\begin_layout Itemize
Duchon spline (bs="ds", m=c(1, 0.5))
\end_layout

\begin_layout Itemize
Thin plate spline with rotated covariates (bs="tp") 
\end_layout

\end_deeper
\begin_layout Itemize
Tensor product smooths
\end_layout

\begin_deeper
\begin_layout Itemize
Thin plate spline (bs="tp") 
\end_layout

\begin_layout Itemize
Thin plate spline with rotated covariates (bs="tp")
\end_layout

\end_deeper
\begin_layout Itemize
Non-spatially explicit models
\end_layout

\begin_deeper
\begin_layout Itemize
Horvitz-Thompson 
\end_layout

\begin_layout Itemize
Horvitz-Thompson stratified with 2 strata: 
\begin_inset Formula $x≤0.5$
\end_inset

 and 
\begin_inset Formula $x>0.5$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Standard
In the rotated covariate case, the coordinates were rotated through 45º
 by the rotation matrix: 
\begin_inset Formula 
\[
R=\begin{pmatrix}cos(\pi/4) & -sin(\pi/4)\\
sin(\pi/4) & cos(\pi/4)
\end{pmatrix}
\]

\end_inset


\end_layout

\begin_layout Subsection
Detection functions
\end_layout

\begin_layout Itemize
“rl_002”: right to left, but decreasing the detectability (i.e., decreasing
 the effective strip width).
 
\end_layout

\begin_layout Itemize
“rl_001”: right to left, but severely decreasing the detectability (i.e.,
 decreasing the effective strip width).
 
\end_layout

\begin_layout Subsection
Designs
\end_layout

\begin_layout Subsubsection
Design 1: zig-zag with straight line
\end_layout

\begin_layout Standard
This is supposed to mimic the situation in which a zig-zag design went well
 on the left side of the study area, but not realised in the middle of the
 survey (perhaps due to bad weather), then to the left we have a lonely
 transect (perhaps weather picked-up).
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

<<designs, echo=FALSE, fig.width=4, fig.height=4>>=
\end_layout

\begin_layout Plain Layout

n_segs <- 10
\end_layout

\begin_layout Plain Layout

zz <- data.frame(x = c(seq(0, 0.5, len=n_segs), seq(0.5, 1, len=n_segs)),
\end_layout

\begin_layout Plain Layout

                 y = c(seq(0, 1, len=n_segs), seq(1, 0, len=n_segs)), 
\end_layout

\begin_layout Plain Layout

                 leg = c(rep("1", n_segs), rep("2", n_segs)))
\end_layout

\begin_layout Plain Layout

# many zigzags
\end_layout

\begin_layout Plain Layout

mzz <- rbind(zz,zz,zz)
\end_layout

\begin_layout Plain Layout

mzz$x <- mzz$x/3 
\end_layout

\begin_layout Plain Layout

ind <- 1:nrow(zz) 
\end_layout

\begin_layout Plain Layout

mzz$x[ind+nrow(zz)] <- mzz$x[ind+nrow(zz)]+1/3 
\end_layout

\begin_layout Plain Layout

mzz$x[ind+2*nrow(zz)] <- mzz$x[ind+2*nrow(zz)]+2/3
\end_layout

\begin_layout Plain Layout

mzz$leg <- as.numeric(mzz$leg) 
\end_layout

\begin_layout Plain Layout

mzz$leg[ind+nrow(zz)] <- mzz$leg[ind+nrow(zz)]+2 
\end_layout

\begin_layout Plain Layout

mzz$leg[ind+2*nrow(zz)] <- mzz$leg[ind+2*nrow(zz)]+4 
\end_layout

\begin_layout Plain Layout

mzz$leg <- as.character(mzz$leg)
\end_layout

\begin_layout Plain Layout

zzl <- rbind.data.frame(mzz, 
\end_layout

\begin_layout Plain Layout

                        data.frame(x = rep(2.8, 10), 
\end_layout

\begin_layout Plain Layout

                                    y = seq(0, 1, len=10), 
\end_layout

\begin_layout Plain Layout

                              leg = rep(as.character(max(as.numeric(mzz$leg))+1),
 10)))
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

plot(c(0,3),c(0,1), type="n", xlab="x", ylab="y", asp=1) 
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

for(i in unique(zzl$leg)){ 
\end_layout

\begin_layout Plain Layout

  lines(zzl[,c("x","y")][zzl$leg==i,]) 
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

lines(c(0,3,3,0,0), c(0,0,1,1,0))
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Realised effort for design 1: zig-zag with straight line.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Metrics
\end_layout

\begin_layout Subsection
Bias
\end_layout

\begin_layout Standard
We can simply calculate the bias (
\begin_inset Formula $N_{\text{truth}}-\hat{N}$
\end_inset

) and plot boxplots of these values, however this does not get to the uncertaint
y, which we're more interested in...
\end_layout

\begin_layout Subsection
Where does the truth lie in the distribution of the model?
\end_layout

\begin_layout Standard
If we know 
\begin_inset Formula $N_{\text{truth}}$
\end_inset

 then at what quantile does it lie in the distribution implied by the model,
 so find 
\begin_inset Formula $\mathbb{P}[N_{\text{truth}}\leq\hat{N}]$
\end_inset

.
 Here we assume log-normally distributed 
\begin_inset Formula $\hat{N}$
\end_inset

, so we can use 
\family typewriter
plnorm
\family default
 in R to calculate the value we require.
 This summary statistic gives some idea of both bias and variance.
\end_layout

\begin_layout Standard
If the distribution of the statistic is skewed to either end then we can
 infer under or over estimation of abundance.
 Flat distribution is good, a "dome" in the middle indicates a conservative
 estimate (CIs slightly too wide), which we like.
 
\end_layout

\begin_layout Standard
An example of plots of this statistic is given in Figure...
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

<<fig.width=9, fig.height=3, echo=FALSE, message=FALSE, warning=FALSE>>=
\end_layout

\begin_layout Plain Layout

# an example in self-confidence
\end_layout

\begin_layout Plain Layout

# quick plot to show what those plots should look like in different 
\end_layout

\begin_layout Plain Layout

# situations
\end_layout

\begin_layout Plain Layout

library(ggplot2)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

# number of reps 
\end_layout

\begin_layout Plain Layout

n <- 1000
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

# when things go "right" -- flat distribution 
\end_layout

\begin_layout Plain Layout

dat <- data.frame(scenario = "ok",quantile = runif(n))
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

# spike on the left => negative bias
\end_layout

\begin_layout Plain Layout

nb <- rexp(2*n, 2) 
\end_layout

\begin_layout Plain Layout

nb <- nb[nb<1 & nb >0] 
\end_layout

\begin_layout Plain Layout

nb <- nb[1:1000] 
\end_layout

\begin_layout Plain Layout

dat <- rbind(dat,data.frame(scenario = "-ve bias", quantile = nb))
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

# spike on the right => positive bias 
\end_layout

\begin_layout Plain Layout

nb <- 1-rexp(2*n, 2) 
\end_layout

\begin_layout Plain Layout

nb <- nb[nb<1 & nb >0] 
\end_layout

\begin_layout Plain Layout

nb <- nb[1:1000] 
\end_layout

\begin_layout Plain Layout

dat <- rbind(dat, data.frame(scenario = "+ve bias", quantile = nb))
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

# what we'd like to see 
\end_layout

\begin_layout Plain Layout

nb <- rnorm(2*n, mean=0.5, sd=0.35) 
\end_layout

\begin_layout Plain Layout

nb <- nb[nb<1 & nb >0] 
\end_layout

\begin_layout Plain Layout

nb <- nb[1:1000] 
\end_layout

\begin_layout Plain Layout

dat <- rbind(dat, data.frame(scenario = "conservative", quantile = nb))
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

p <- ggplot(dat) +
\end_layout

\begin_layout Plain Layout

      geom_histogram(aes(quantile), binwidth=0.05)+
\end_layout

\begin_layout Plain Layout

      scale_x_continuous(limits=c(0,1))+
\end_layout

\begin_layout Plain Layout

      facet_wrap(~scenario, nrow=1) +
\end_layout

\begin_layout Plain Layout

      theme_minimal()
\end_layout

\begin_layout Plain Layout

print(p)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Illustration of the 
\begin_inset Quotes eld
\end_inset

self-confidence
\begin_inset Quotes erd
\end_inset

 measure.
 From left to right: 
\begin_inset Quotes eld
\end_inset

ok
\begin_inset Quotes erd
\end_inset

 denotes shows a plot with flat quantile distribution (no problems), 
\begin_inset Quotes eld
\end_inset

-ve bias
\begin_inset Quotes erd
\end_inset

 shows a large spike at zero indicating negative bias, 
\begin_inset Quotes eld
\end_inset

+ve bias
\begin_inset Quotes erd
\end_inset

 shows the spike at 1 indicating positive bias, 
\begin_inset Quotes eld
\end_inset

conservative
\begin_inset Quotes erd
\end_inset

 shows behaviour where the confidence intervals are rather larger than 
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Examples
\end_layout

\begin_layout Itemize
some designs that are clearly iffy
\end_layout

\begin_deeper
\begin_layout Itemize
something where the covariate matters
\end_layout

\begin_layout Itemize
reasonable designs actually 
\emph on
will
\emph default
 pass the test
\end_layout

\end_deeper
\begin_layout Section
Software
\end_layout

\begin_layout Itemize
Fitting was done in 
\family typewriter
Distance
\family default
 (R package version 0.9.6) and 
\family typewriter
dsm
\family default
 (R package version 2.2.12).
\end_layout

\begin_deeper
\begin_layout Itemize
Simulations were generated using 
\family typewriter
DSsim
\family default
 (R package version 1.0.4).
\end_layout

\end_deeper
\begin_layout Section
Discussion 
\end_layout

\begin_layout Standard
(of things that are still negotiable to include post-Bled :)
\end_layout

\begin_layout Itemize
note that we only need consider these simple gradients not multiples, as
 we can consider each as a stratified version of a 
\begin_inset Quotes eld
\end_inset

multiple ripple
\begin_inset Quotes erd
\end_inset

 setup (I think this makes sense)
\end_layout

\begin_layout Part*
Appendices
\end_layout

\begin_layout Section*
Appendix 1 - Mathematical equivalence between HT and DSM
\end_layout

\begin_layout Standard
This should go somewhere, why not here?
\end_layout

\begin_layout Section*
Appendix 2 - Data format for 
\family typewriter
Distance
\family default
 and 
\family typewriter
dsm
\end_layout

\begin_layout Standard
In this appendix we describe the data format required for the two packages
 used above.
 The text below is adapted from their respective manuals.
\end_layout

\begin_layout Subsection*

\family typewriter
Distance
\end_layout

\begin_layout Standard
A single 
\family typewriter
data.frame 
\family default
should be provided to
\family typewriter
 Distance
\family default
 to fit a detection function, or to estimate abundance using the HT estimator.
 To simply fit a detection function we require the following columns in
 our data:
\end_layout

\begin_layout Itemize

\family typewriter
distance
\family default
 observed perpendicular distance to observation from the line
\end_layout

\begin_layout Itemize

\family typewriter
object
\family default
 an unique identifier for the observation
\end_layout

\begin_layout Standard
If one wishes to estimate abundance, the following columns are also required:
\end_layout

\begin_layout Itemize

\family typewriter
Sample.Label
\family default
 Identifier for the sample (transect) 
\end_layout

\begin_layout Itemize

\family typewriter
Effort
\family default
 effort for this transect (transect length) 
\end_layout

\begin_layout Itemize

\family typewriter
Region.Label
\family default
 label for a given stratum
\end_layout

\begin_layout Itemize

\family typewriter
Area
\family default
 area of the strata
\end_layout

\begin_layout Standard
Each row corresponds to one observation.
 In some cases a given transect or even stratum may contain zero observations.
 In this case the transect(s) are still included, along with their effort,
 but their corresponding 
\family typewriter
object
\family default
 and 
\family typewriter
distance
\family default
 fields are set to 
\begin_inset Quotes eld
\end_inset

not available
\begin_inset Quotes erd
\end_inset

 (in R 
\begin_inset Quotes eld
\end_inset


\family typewriter
NA
\family default

\begin_inset Quotes erd
\end_inset

).
\end_layout

\begin_layout Subsection*

\family typewriter
dsm
\end_layout

\begin_layout Standard
Two 
\family typewriter
data.frame
\family default
s must be provided to 
\family typewriter
dsm
\family default
.
 They are referred to as 
\family typewriter
observation.data
\family default
 and 
\family typewriter
segment.data
\family default
.
 The 
\family typewriter
segment.data
\family default
 table has the sample identifiers which define the segments, the corresponding
 effort (line length) expended and the environmental covariates that will
 be used to model abundance/density.
 
\family typewriter
observation.data
\family default
 provides a link table between the observations used in the detection function
 and the samples (segments), so that we can aggregate the observations to
 the segments (i.e.
 
\family typewriter
observation.data
\family default
 is a "look-up table" between the observations and the segments).
\end_layout

\begin_layout Subsubsection*

\family typewriter
observation.data
\end_layout

\begin_layout Standard
The observation 
\family typewriter
data.frame
\family default
 must have (at least) the following columns: 
\end_layout

\begin_layout Itemize

\family typewriter
object
\family default
 unique object identifier
\end_layout

\begin_layout Itemize

\family typewriter
Sample.Label
\family default
 the identifier for the segment that the observation occurred in 
\end_layout

\begin_layout Itemize

\family typewriter
size
\family default
 the size of each observed group (e.g 1 if all animals occurred individually)
 
\end_layout

\begin_layout Itemize

\family typewriter
distance
\family default
 distance to observation
\end_layout

\begin_layout Standard
One can often also use 
\family typewriter
observation.data
\family default
 to fit a detection function (so additional columns for detection function
 covariates are allowed in this table).
\end_layout

\begin_layout Subsection*

\family typewriter
segment.data
\end_layout

\begin_layout Standard
The segment 
\family typewriter
data.frame
\family default
 must have (at least) the following columns:
\end_layout

\begin_layout Itemize

\family typewriter
Effort
\family default
 the effort (in terms of length of the segment) 
\end_layout

\begin_layout Itemize

\family typewriter
Sample.Label
\family default
 identifier for the segment (unique!) 
\end_layout

\begin_layout Itemize
??? environmental covariates, for example: location (projected latitude
 and longitude), and other relevant covariates (sea surface temperature,
 bathymetry etc).
 
\end_layout

\end_body
\end_document
